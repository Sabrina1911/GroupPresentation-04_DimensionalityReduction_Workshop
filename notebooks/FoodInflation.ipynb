{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e32640fb",
   "metadata": {},
   "source": [
    "# Food Price Inflation — OOP Pipeline (Enhanced, Canada)\n",
    "\n",
    "**Term Project Topic:** *Forecasting Food Price Inflation for Policy Response*  \n",
    "**New Data Source Added:** *World Bank — Food Prices for Nutrition (Canada subset, 2017–2024)*  \n",
    "**Legacy Source:** *World Bank CPI / Food Price Inflation (Canada)*\n",
    "\n",
    "> **Data paths (edit if needed):**  \n",
    "> - `../data/API_FP.CPI.TOTL.ZG_DS2_en_csv_v2_23195.csv` *(CPI, previously used)*  \n",
    "> - `../data/2abd45d3-18a3-4ed6-8799-524647bb719a_Data.csv` *(Nutrition main data)*  \n",
    "> - `../data/2abd45d3-18a3-4ed6-8799-524647bb719a_Series - Metadata.csv` *(Nutrition metadata)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d4deb8",
   "metadata": {},
   "source": [
    "## 1‑Minute Explanation (What, Why, How)\n",
    "We added the **Food Prices for Nutrition** dataset (Canada, 2017–2024), which measures the *cost and affordability* of healthy and nutrient‑adequate diets (PPP/day and ratios). This complements CPI and global indices by capturing **affordability stress** on households. Our OOP notebook loads, cleans, and merges these sources; applies **Missing‑values ratio**, **Low‑variance**, **High‑correlation filter**, **PCA**, **Random Forest importance**, and **Sequential Feature Selection**; then performs **STL decomposition** and **ARIMA/SARIMAX** forecasting (with optional exogenous features). Finally, we run **ADF** and **Granger** tests to probe stationarity and predictive relationships. The output is a compact feature set and a short‑horizon forecast suitable for **early‑warning dashboards** and **policy decisions**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25275003",
   "metadata": {},
   "source": [
    "## Hypothesis — Previous vs Revised (Unit 3 framing)\n",
    "\n",
    "**Previous (from prior submission):**  \n",
    "- **H₀:** No significant monotonic trend in Canada’s annual food inflation (1960–2024).  \n",
    "- **H₁:** A significant trend exists.  \n",
    "- **Result:** *p* < 0.05, trend decreasing → **Reject H₀**.\n",
    "\n",
    "**Revised (with new dataset & predictive framing):**  \n",
    "- **H₀ (Predictive Null):** *Affordability/Cost‑of‑Diet* indicators (nutrition dataset) **do not** add statistically significant predictive power for Canada’s monthly/annual food inflation beyond CPI’s own history.  \n",
    "- **H₁ (Predictive Alt):** *Affordability/Cost‑of‑Diet* indicators **do** add significant predictive power (e.g., Granger‑cause CPI or improve forecast accuracy in ARIMAX/X models).\n",
    "\n",
    "**Testing Approach:** ADF for stationarity; STL for structure; Granger causality (*x*→CPI); PCA and model‑based importance for dimensionality; ARIMA/SARIMAX for forecasting with exogenous features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71325d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Optional, Dict, List, Tuple\n",
    "\n",
    "# Stats & TS\n",
    "from statsmodels.tsa.stattools import adfuller, grangercausalitytests\n",
    "from statsmodels.tsa.seasonal import STL\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "\n",
    "# ML\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "# Viz: per your class rules — matplotlib only, one plot per figure, no explicit colors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.width', 140)\n",
    "pd.set_option('display.max_columns', 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29cd79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPaths:\n",
    "    def __init__(self,\n",
    "                 cpi_path: str = '../data/API_FP.CPI.TOTL.ZG_DS2_en_csv_v2_23195.csv',\n",
    "                 nutrition_data_path: str = '../data/2abd45d3-18a3-4ed6-8799-524647bb719a_Data.csv',\n",
    "                 nutrition_meta_path: str = '../data/2abd45d3-18a3-4ed6-8799-524647bb719a_Series - Metadata.csv'):\n",
    "        self.cpi_path = cpi_path\n",
    "        self.nutrition_data_path = nutrition_data_path\n",
    "        self.nutrition_meta_path = nutrition_meta_path\n",
    "\n",
    "    def as_dict(self) -> Dict[str, str]:\n",
    "        return {'cpi_path': self.cpi_path,\n",
    "                'nutrition_data_path': self.nutrition_data_path,\n",
    "                'nutrition_meta_path': self.nutrition_meta_path}\n",
    "\n",
    "paths = DataPaths()\n",
    "paths.as_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9b82bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CPILoader:\n",
    "    def __init__(self, path: str):\n",
    "        self.path = path\n",
    "        self.df: Optional[pd.DataFrame] = None\n",
    "\n",
    "    def load(self) -> pd.DataFrame:\n",
    "        self.df = pd.read_csv(self.path, skiprows=4)\n",
    "        return self.df\n",
    "\n",
    "    def canada_long_since(self, year_min: int = 2017) -> pd.DataFrame:\n",
    "        if self.df is None:\n",
    "            self.load()\n",
    "        years = [c for c in self.df.columns if c.isdigit()]\n",
    "        keep_cols = ['Indicator Name', 'Country Name'] + years\n",
    "        can = self.df[self.df['Country Name'] == 'Canada'][keep_cols]\n",
    "        long_df = can.melt(id_vars=['Country Name','Indicator Name'], var_name='Year', value_name='CPI_Value')\n",
    "        long_df['Year'] = long_df['Year'].astype(int)\n",
    "        long_df = long_df[long_df['Year'] >= year_min]\n",
    "        return long_df\n",
    "\n",
    "class NutritionLoader:\n",
    "    def __init__(self, data_path: str, meta_path: Optional[str] = None):\n",
    "        self.data_path = data_path\n",
    "        self.meta_path = meta_path\n",
    "        self.df: Optional[pd.DataFrame] = None\n",
    "        self.meta: Optional[pd.DataFrame] = None\n",
    "\n",
    "    def load(self) -> Tuple[pd.DataFrame, Optional[pd.DataFrame]]:\n",
    "        self.df = pd.read_csv(self.data_path)\n",
    "        if self.meta_path and os.path.exists(self.meta_path):\n",
    "            self.meta = pd.read_csv(self.meta_path)\n",
    "        return self.df, self.meta\n",
    "\n",
    "    def canada_since(self, year_min: int = 2017) -> pd.DataFrame:\n",
    "        if self.df is None:\n",
    "            self.load()\n",
    "        df = self.df.rename(columns={'Country Name':'Country','Time':'Year'})\n",
    "        df = df[df['Country']=='Canada'].copy()\n",
    "        df['Year'] = df['Year'].astype(int)\n",
    "        df = df[df['Year'] >= year_min]\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1b3db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataMerger:\n",
    "    @staticmethod\n",
    "    def merge_on_year(cpi_long: pd.DataFrame, nutrition_can: pd.DataFrame) -> pd.DataFrame:\n",
    "        return pd.merge(cpi_long, nutrition_can, on='Year', how='inner')\n",
    "\n",
    "class FeatureEngineer:\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df.copy()\n",
    "\n",
    "    def drop_high_missing(self, threshold: float = 0.4):\n",
    "        mask = self.df.isna().mean() < threshold\n",
    "        self.df = self.df.loc[:, mask]\n",
    "        return self\n",
    "\n",
    "    def drop_low_variance(self, min_std: float = 0.01):\n",
    "        num = self.df.select_dtypes(include=[np.number])\n",
    "        keep = num.loc[:, num.std() > min_std].columns.tolist()\n",
    "        others = [c for c in self.df.columns if c not in num.columns]\n",
    "        self.df = self.df[keep + others]\n",
    "        return self\n",
    "\n",
    "    def drop_high_correlation(self, corr_thresh: float = 0.85, protect: Optional[List[str]] = None):\n",
    "        if protect is None: protect = []\n",
    "        num = self.df.select_dtypes(include=[np.number])\n",
    "        if num.shape[1] == 0:\n",
    "            return self\n",
    "        corr = num.corr()\n",
    "        to_drop = set()\n",
    "        cols = corr.columns\n",
    "        for i in range(len(cols)):\n",
    "            for j in range(i+1, len(cols)):\n",
    "                if abs(corr.iloc[i,j]) > corr_thresh:\n",
    "                    c2 = cols[j]\n",
    "                    if c2 not in protect:\n",
    "                        to_drop.add(c2)\n",
    "        self.df = self.df.drop(columns=list(to_drop), errors='ignore')\n",
    "        return self\n",
    "\n",
    "    def get(self) -> pd.DataFrame:\n",
    "        return self.df\n",
    "\n",
    "    @staticmethod\n",
    "    def show_corr(df: pd.DataFrame, title: str = 'Correlation Matrix'):\n",
    "        num = df.select_dtypes(include=[np.number])\n",
    "        if num.shape[1] == 0:\n",
    "            print('No numeric columns to plot.')\n",
    "            return\n",
    "        corr = num.corr()\n",
    "        plt.figure(figsize=(8,6))\n",
    "        plt.imshow(corr.values, aspect='auto')\n",
    "        plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
    "        plt.yticks(range(len(corr.index)), corr.index)\n",
    "        plt.title(title)\n",
    "        plt.colorbar()\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa70829",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DimensionalityReducer:\n",
    "    def __init__(self, df: pd.DataFrame, target_col: str = 'CPI_Value'):\n",
    "        self.df = df.copy()\n",
    "        self.target_col = target_col\n",
    "        self.scaler: Optional[StandardScaler] = None\n",
    "        self.pca: Optional[PCA] = None\n",
    "\n",
    "    def prepare(self, exclude: Optional[List[str]] = None):\n",
    "        if exclude is None: exclude = []\n",
    "        X = self.df.select_dtypes(include=[np.number]).drop(columns=list(set(exclude + ['Year'])), errors='ignore')\n",
    "        y = self.df[self.target_col] if self.target_col in self.df.columns else None\n",
    "        return X, y\n",
    "\n",
    "    def fit_pca(self, n_components: int = 2):\n",
    "        X, _ = self.prepare(exclude=[self.target_col])\n",
    "        self.scaler = StandardScaler()\n",
    "        Xs = self.scaler.fit_transform(X)\n",
    "        self.pca = PCA(n_components=n_components)\n",
    "        Xp = self.pca.fit_transform(Xs)\n",
    "        return Xp, list(self.pca.explained_variance_ratio_)\n",
    "\n",
    "    def plot_variance(self):\n",
    "        if self.pca is None:\n",
    "            print('Run fit_pca first.')\n",
    "            return\n",
    "        evr = self.pca.explained_variance_ratio_\n",
    "        plt.figure()\n",
    "        plt.bar(range(1, len(evr)+1), np.array(evr)*100)\n",
    "        plt.xlabel('Principal Component')\n",
    "        plt.ylabel('Variance Explained (%)')\n",
    "        plt.title('PCA — Variance Explained')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "class ModelSelector:\n",
    "    def __init__(self, df: pd.DataFrame, target_col: str = 'CPI_Value'):\n",
    "        self.df = df.copy()\n",
    "        self.target_col = target_col\n",
    "\n",
    "    def rf_importance(self, exclude: Optional[List[str]] = None) -> pd.DataFrame:\n",
    "        if exclude is None: exclude = []\n",
    "        X = self.df.select_dtypes(include=[np.number]).drop(columns=list(set(exclude + [self.target_col])), errors='ignore')\n",
    "        y = self.df[self.target_col]\n",
    "        rf = RandomForestRegressor(random_state=42)\n",
    "        rf.fit(X, y)\n",
    "        imp = pd.DataFrame({'Feature': X.columns, 'Importance': rf.feature_importances_})\n",
    "        return imp.sort_values('Importance', ascending=False, ignore_index=True)\n",
    "\n",
    "    def sequential(self, k: int = 3, direction: str = 'forward', exclude: Optional[List[str]] = None) -> List[str]:\n",
    "        if exclude is None: exclude = []\n",
    "        X = self.df.select_dtypes(include=[np.number]).drop(columns=list(set(exclude + [self.target_col])), errors='ignore')\n",
    "        y = self.df[self.target_col]\n",
    "        model = LinearRegression()\n",
    "        sfs = SequentialFeatureSelector(model, n_features_to_select=min(k, X.shape[1]), direction=direction)\n",
    "        sfs.fit(X, y)\n",
    "        return X.columns[sfs.get_support()].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ba4d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HypothesisTester:\n",
    "    @staticmethod\n",
    "    def adf(series: pd.Series, maxlag: Optional[int] = None):\n",
    "        series = series.dropna()\n",
    "        stat = adfuller(series, maxlag=maxlag, autolag='AIC')\n",
    "        return {'adf_stat': stat[0], 'p_value': stat[1], 'n_lags': stat[2], 'n_obs': stat[3]}\n",
    "\n",
    "    @staticmethod\n",
    "    def granger(df: pd.DataFrame, x_col: str, y_col: str, maxlag: int = 2):\n",
    "        sub = df[[y_col, x_col]].dropna().copy()\n",
    "        res = grangercausalitytests(sub[[y_col, x_col]], maxlag=maxlag, verbose=False)\n",
    "        return {lag: res[lag][0]['ssr_ftest'][1] for lag in res}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810e5e13",
   "metadata": {},
   "source": [
    "## Pipeline (Load → Merge → Clean → Reduce → Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cade0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "cpi = CPILoader(paths.cpi_path); cpi.load()\n",
    "cpi_long = cpi.canada_long_since(2017)\n",
    "\n",
    "nut = NutritionLoader(paths.nutrition_data_path, paths.nutrition_meta_path); nut.load()\n",
    "nut_can = nut.canada_since(2017)\n",
    "\n",
    "print('Rows (CPI long):', len(cpi_long))\n",
    "print('Rows (Nutrition CAN):', len(nut_can))\n",
    "\n",
    "# Merge\n",
    "merged = DataMerger.merge_on_year(cpi_long, nut_can)\n",
    "print('Merged shape:', merged.shape)\n",
    "merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "172d3618",
   "metadata": {},
   "source": [
    "### Cleanup & Filters (Missing Values, Low Variance, High Correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6755d67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = FeatureEngineer(merged)\n",
    "fe.drop_high_missing(0.4).drop_low_variance(0.01).drop_high_correlation(0.85, protect=['CPI_Value'])\n",
    "clean_df = fe.get()\n",
    "FeatureEngineer.show_corr(clean_df, title='Correlation Matrix — Post Filters')\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcc8f18",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2909df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr = DimensionalityReducer(clean_df, target_col='CPI_Value')\n",
    "_, evr = dr.fit_pca(n_components=2)\n",
    "print('Explained variance ratio:', evr)\n",
    "dr.plot_variance()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0ce7c2",
   "metadata": {},
   "source": [
    "### Random Forest Importance & Sequential Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763b942a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ms = ModelSelector(clean_df, target_col='CPI_Value')\n",
    "imp = ms.rf_importance(exclude=['Year'])\n",
    "imp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4e82d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = ms.sequential(k=3, direction='forward', exclude=['Year'])\n",
    "print('Selected features:', selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721c62cb",
   "metadata": {},
   "source": [
    "## STL Decomposition (Target: CPI_Value)\n",
    "> With annual data (2017–2024), seasonality is limited; monthly data is recommended for stronger seasonal insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b716ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = clean_df[['Year','CPI_Value']].dropna().drop_duplicates().sort_values('Year').set_index('Year')['CPI_Value']\n",
    "period = 12 if len(ts) >= 24 else max(2, len(ts)//2)\n",
    "print('Series length:', len(ts), '| STL period:', period)\n",
    "\n",
    "stl = STL(ts, period=period, robust=True)\n",
    "res = stl.fit()\n",
    "\n",
    "plt.figure(); plt.plot(ts.index, ts.values); plt.title('CPI_Value — Original'); plt.tight_layout(); plt.show()\n",
    "plt.figure(); plt.plot(res.trend.index, res.trend.values); plt.title('CPI_Value — Trend'); plt.tight_layout(); plt.show()\n",
    "plt.figure(); plt.plot(res.seasonal.index, res.seasonal.values); plt.title('CPI_Value — Seasonal'); plt.tight_layout(); plt.show()\n",
    "plt.figure(); plt.plot(res.resid.index, res.resid.values); plt.title('CPI_Value — Residual'); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dbab76",
   "metadata": {},
   "source": [
    "## ARIMA/SARIMAX Forecast\n",
    "We fit a small-order ARIMA and, when available, include exogenous features from `selected` as SARIMAX exog. We then forecast the next 2 periods with naive exog extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9ffdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "series_df = clean_df.sort_values('Year').reset_index(drop=True)\n",
    "endog = series_df['CPI_Value'].astype(float)\n",
    "\n",
    "# Choose exogenous columns if available\n",
    "try:\n",
    "    exog_cols = [c for c in selected if c in series_df.columns]\n",
    "except Exception:\n",
    "    exog_cols = []\n",
    "exog = series_df[exog_cols].astype(float) if exog_cols else None\n",
    "print('Exogenous features used:', exog_cols)\n",
    "\n",
    "order = (1,1,0)\n",
    "seasonal_order = (0,0,0,0)\n",
    "\n",
    "model = SARIMAX(endog, exog=exog, order=order, seasonal_order=seasonal_order,\n",
    "                enforce_stationarity=False, enforce_invertibility=False)\n",
    "res = model.fit(disp=False)\n",
    "print(res.summary())\n",
    "\n",
    "fitted = res.fittedvalues\n",
    "\n",
    "# Forecast\n",
    "n_forecast = 2\n",
    "future_exog = None\n",
    "if exog is not None and len(exog_cols) > 0:\n",
    "    future_exog = pd.concat([exog.iloc[-1:]]*n_forecast, ignore_index=True)\n",
    "\n",
    "pred = res.get_forecast(steps=n_forecast, exog=future_exog)\n",
    "mean_fc = pred.predicted_mean\n",
    "ci = pred.conf_int()\n",
    "\n",
    "last_year = int(series_df['Year'].iloc[-1])\n",
    "fc_index = list(range(last_year+1, last_year+1+n_forecast))\n",
    "\n",
    "plt.figure(); plt.plot(series_df['Year'], endog.values, label='Actual'); plt.plot(series_df['Year'], fitted.values, label='Fitted'); plt.title('ARIMA/SARIMAX — Actual vs Fitted'); plt.legend(); plt.tight_layout(); plt.show()\n",
    "plt.figure(); plt.plot(series_df['Year'], endog.values, label='Actual'); plt.plot(fc_index, mean_fc.values, label='Forecast'); plt.fill_between(fc_index, ci.iloc[:,0].values, ci.iloc[:,1].values, alpha=0.3); plt.title('ARIMA/SARIMAX — Forecast (Next 2)'); plt.legend(); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7543a983",
   "metadata": {},
   "source": [
    "## Hypothesis Testing Cells (ADF & Granger)\n",
    "- **ADF:** Stationarity of `CPI_Value` and top affordability feature.  \n",
    "- **Granger:** Does affordability feature **Granger‑cause** CPI?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbddf9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "adf_cpi = HypothesisTester.adf(series_df['CPI_Value'])\n",
    "print('ADF — CPI_Value:', adf_cpi)\n",
    "\n",
    "# Heuristic: pick a nutrition feature that looks like a cost/PPP measure\n",
    "cand = [c for c in clean_df.columns if ('healthy' in c.lower() and 'ppp' in c.lower()) or ('cost of' in c.lower() and 'diet' in c.lower())]\n",
    "if cand:\n",
    "    xcol = cand[0]\n",
    "    print('Using feature for tests:', xcol)\n",
    "    adf_x = HypothesisTester.adf(series_df[xcol])\n",
    "    print('ADF —', xcol, ':', adf_x)\n",
    "    gr = HypothesisTester.granger(series_df[[xcol,'CPI_Value']].join(series_df['Year']), x_col=xcol, y_col='CPI_Value', maxlag=2)\n",
    "    print('Granger p-values (x → CPI):', gr)\n",
    "else:\n",
    "    print('No cost/PPP nutrition feature auto-detected. Manually set xcol to test Granger causality.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f14a882",
   "metadata": {},
   "source": [
    "## 3–5 Minute Presentation Outline (Hard Stop at 5)\n",
    "1. **Context (≤20s):** Food inflation harms low‑income households; need early warning.\n",
    "2. **Data (≤40s):** CPI + **Nutrition affordability** (PPP/day, ratios). Why this is new & relevant.\n",
    "3. **Pipeline (≤90s):** OOP loaders → merge → missing/variance/correlation filters → PCA → RF/Selection → STL → ARIMA.\n",
    "4. **Findings (≤60s):** Key features, PCA variance %, ADF/Granger hints, 2‑step forecast.\n",
    "5. **Policy Hook (≤30s):** Signals of affordability stress can prompt targeted subsidies/imports.\n",
    "6. **Close (≤20s):** Next: monthly granularity, proper exog forecasting, backtesting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fea59ff",
   "metadata": {},
   "source": [
    "## Quick TOC\n",
    "- [1-Minute Explanation](#one-minute)\n",
    "- [100-Word Summary](#hundred)\n",
    "- [Hypothesis — Previous vs Revised](#hypo)\n",
    "- [Loaders & Paths (OOP)](#oop)\n",
    "- [Data Dictionary (from Metadata)](#dict)\n",
    "- [Pipeline & Cleaning](#pipe)\n",
    "- [PCA & Feature Selection](#pca)\n",
    "- [Time Series: STL & ARIMA](#ts)\n",
    "- [Hypothesis Tests: ADF & Granger](#tests)\n",
    "- [Presentation Outline (3–5 min)](#pres)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59714841",
   "metadata": {},
   "source": [
    "<a id=\"hundred\"></a>\n",
    "\n",
    "## 100-Word Summary\n",
    "We integrate the World Bank Food Prices for Nutrition (Canada, 2017–2024) with our CPI series to forecast domestic food price inflation with richer socioeconomic context. Nutrition indicators measure the daily PPP cost and affordability of healthy and nutrient‑adequate diets. Using an OOP pipeline, we load, merge, and prepare data, apply missing‑values, low‑variance, and high‑correlation filters, then reduce dimensionality via PCA, Random Forest importance, and forward/backward feature selection. Finally, we perform STL decomposition, ARIMA/SARIMAX forecasting with exogenous features, and ADF/Granger tests. Our goal is an early‑warning signal for policymakers, linking affordability stress to inflation risks and informing targeted interventions. This concise update reflects the revised hypothesis focus and modeling scope.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93d7e92",
   "metadata": {},
   "source": [
    "<a id=\"one-minute\"></a>\n",
    "\n",
    "## 1-Minute Explanation (verbal)\n",
    "- **What:** Add *Food Prices for Nutrition* (Canada) to CPI to capture **affordability** of healthy diets (PPP/day, ratios).\n",
    "- **Why:** Inflation hurts low‑income households; affordability signals **policy urgency** beyond CPI levels.\n",
    "- **How:** OOP notebook → loaders → merge → filters (missing/variance/correlation) → PCA → RF importance → forward/backward selection → STL → ARIMA/SARIMAX → ADF/Granger.\n",
    "- **Outcome:** Compact, interpretable features; short‑horizon forecast; early‑warning indicators for targeted subsidies/imports.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb9f804",
   "metadata": {},
   "source": [
    "<a id=\"hypo\"></a>\n",
    "\n",
    "## Hypothesis Testing — What the tests mean\n",
    "- **ADF (Augmented Dickey–Fuller):** Checks stationarity; non‑stationary series often need differencing before ARIMA. We test `CPI_Value` and key affordability features.\n",
    "- **Granger Causality:** If past values of X improve prediction of Y (beyond Y’s own past), we say X *Granger‑causes* Y. Here: affordability → CPI.\n",
    "- **Model‑based Evidence:** PCA (variance captured), Random Forest importance (nonlinear ranking), and sequential selection (parsimonious linear subset) support feature relevance beyond pure causality tests.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd1d09a",
   "metadata": {},
   "source": [
    "<a id=\"ts\"></a>\n",
    "\n",
    "## Time Series — What we analyze\n",
    "- **STL Decomposition:** Separates trend, seasonal, and residual components in `CPI_Value`. With annual data, seasonality is limited; monthly CPI is stronger.\n",
    "- **ARIMA/SARIMAX:** ARIMA models autocorrelation; SARIMAX adds **exogenous** drivers (affordability features). We provide a simple baseline and recommend monthly data + order search for production.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3f536c",
   "metadata": {},
   "source": [
    "<a id=\"dict\"></a>\n",
    "\n",
    "## Data Dictionary (auto-extracted from metadata if available)\n",
    "The cell below reads the series metadata file to display indicator names, units, and definitions for fast reference during your 1‑minute explanation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd7facd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data dictionary preview (if metadata exists)\n",
    "try:\n",
    "    _meta_path = paths.nutrition_meta_path\n",
    "    if os.path.exists(_meta_path):\n",
    "        _meta = pd.read_csv(_meta_path)\n",
    "        cols = [c for c in _meta.columns if any(k in c.lower() for k in ['name','indicator','unit','definition','topic','series'])]\n",
    "        display(_meta[cols].head(20))\n",
    "    else:\n",
    "        print('Metadata file not found at:', _meta_path)\n",
    "except Exception as e:\n",
    "    print('Metadata read error:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ab26dc",
   "metadata": {},
   "source": [
    "<a id=\"pca\"></a>\n",
    "\n",
    "## Feature Selection — Backward (in addition to Forward)\n",
    "We add backward elimination to complement forward selection, as requested in the rubric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd885e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward selection (Linear Regression baseline)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "ms_back = ModelSelector(clean_df, target_col='CPI_Value')\n",
    "X_back = clean_df.select_dtypes(include=[np.number]).drop(columns=['Year','CPI_Value'], errors='ignore')\n",
    "y_back = clean_df['CPI_Value']\n",
    "\n",
    "backward_selector = SequentialFeatureSelector(LinearRegression(), n_features_to_select=min(3, X_back.shape[1]), direction='backward')\n",
    "backward_selector.fit(X_back, y_back)\n",
    "back_selected = X_back.columns[backward_selector.get_support()].tolist()\n",
    "print('Backward-selected features:', back_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24fcbbf",
   "metadata": {},
   "source": [
    "<a id=\"oop\"></a>\n",
    "\n",
    "*(OOP loaders and paths defined above.)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac8a89e",
   "metadata": {},
   "source": [
    "<a id=\"pipe\"></a>\n",
    "\n",
    "*(Pipeline and cleaning steps executed above.)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f005f3",
   "metadata": {},
   "source": [
    "<a id=\"ts\"></a>\n",
    "\n",
    "*(STL & ARIMA sections included above.)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb87e1b",
   "metadata": {},
   "source": [
    "<a id=\"tests\"></a>\n",
    "\n",
    "*(ADF & Granger testing cells included above.)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa41274",
   "metadata": {},
   "source": [
    "<a id=\"pres\"></a>\n",
    "\n",
    "*(Presentation outline included above.)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1796bae8",
   "metadata": {},
   "source": [
    "## Monthly CPI Pipeline (Optional — Recommended for Stronger STL/ARIMA)\n",
    "\n",
    "This section reuses the same OOP approach but with **monthly CPI** (more data points ⇒ better seasonality & ARIMA stability).  \n",
    "**Expected input file:** `../data/canada_cpi_monthly.csv` with columns:\n",
    "- `Date` — first day of month (e.g., `2010-01-01`), or `YYYY-MM` parseable by pandas\n",
    "- `CPI_Value` — monthly CPI (target). You can substitute *Food* CPI or a food inflation rate if available (rename to `CPI_Value`).\n",
    "\n",
    "**Nutrition (annual) → monthly join:** We merge by year and forward-fill to monthly frequency so affordability features are available each month. Replace with truly monthly exogenous data when you have it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed26455",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MonthlyCPILoader:\n",
    "    def __init__(self, path: str = '../data/canada_cpi_monthly.csv'):\n",
    "        self.path = path\n",
    "        self.df = None\n",
    "\n",
    "    def load(self):\n",
    "        df = pd.read_csv(self.path)\n",
    "        # Parse Date column flexibly\n",
    "        if 'Date' not in df.columns:\n",
    "            raise ValueError('Expected a Date column in monthly CPI file.')\n",
    "        df['Date'] = pd.to_datetime(df['Date'])\n",
    "        if 'CPI_Value' not in df.columns:\n",
    "            # try to find a likely target column\n",
    "            candidates = [c for c in df.columns if c.lower().startswith('cpi') or 'value' in c.lower()]\n",
    "            if not candidates:\n",
    "                raise ValueError('Expected a CPI_Value column; add/rename your target to CPI_Value.')\n",
    "            df = df.rename(columns={candidates[0]: 'CPI_Value'})\n",
    "        df = df.sort_values('Date').reset_index(drop=True)\n",
    "        self.df = df\n",
    "        return df\n",
    "\n",
    "    def ensure_monthly(self):\n",
    "        if self.df is None:\n",
    "            self.load()\n",
    "        df = self.df.set_index('Date').asfreq('MS')  # month start\n",
    "        self.df = df.reset_index()\n",
    "        return self.df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "107b9f18",
   "metadata": {},
   "source": [
    "### Run Monthly Pipeline (Loads file if present; prints guidance otherwise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37356cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    mloader = MonthlyCPILoader('../data/canada_cpi_monthly.csv')\n",
    "    monthly = mloader.load()\n",
    "    monthly = mloader.ensure_monthly()\n",
    "    monthly['Year'] = monthly['Date'].dt.year\n",
    "    print('Monthly CPI rows:', len(monthly))\n",
    "    display(monthly.head())\n",
    "\n",
    "    # Bring in annual nutrition → monthly via Year join\n",
    "    # Reuse previously loaded `nut_can` (annual) if available; otherwise load\n",
    "    try:\n",
    "        _nut = nut_can.copy()\n",
    "    except NameError:\n",
    "        nut = NutritionLoader(paths.nutrition_data_path, paths.nutrition_meta_path); nut.load()\n",
    "        _nut = nut.canada_since(2017)\n",
    "\n",
    "    mmerge = pd.merge(monthly, _nut, on='Year', how='left')\n",
    "    # Forward-fill any remaining missing values (e.g., at start of year)\n",
    "    mmerge = mmerge.sort_values('Date').ffill()\n",
    "    print('Monthly merged shape:', mmerge.shape)\n",
    "    display(mmerge.head())\n",
    "\n",
    "    # Apply the same cleaning/filters using FeatureEngineer\n",
    "    mfe = FeatureEngineer(mmerge)\n",
    "    mfe.drop_high_missing(0.4).drop_low_variance(0.001).drop_high_correlation(0.9, protect=['CPI_Value'])\n",
    "    mclean = mfe.get()\n",
    "    FeatureEngineer.show_corr(mclean, title='Monthly — Correlation Matrix (Post Filters)')\n",
    "\n",
    "    # PCA on monthly data\n",
    "    mdr = DimensionalityReducer(mclean, target_col='CPI_Value')\n",
    "    _, mevr = mdr.fit_pca(n_components=3)\n",
    "    print('Monthly PCA explained variance ratio:', mevr)\n",
    "    mdr.plot_variance()\n",
    "\n",
    "    # Feature importance & selection on monthly\n",
    "    msel = ModelSelector(mclean, target_col='CPI_Value')\n",
    "    mimp = msel.rf_importance(exclude=['Year'])\n",
    "    display(mimp.head(10))\n",
    "    mselected_fwd = msel.sequential(k=5, direction='forward', exclude=['Year'])\n",
    "    print('Monthly selected (forward):', mselected_fwd)\n",
    "\n",
    "    # STL with period=12\n",
    "    mts = mclean[['Date','CPI_Value']].dropna().sort_values('Date').set_index('Date')['CPI_Value']\n",
    "    from statsmodels.tsa.seasonal import STL\n",
    "    stl_m = STL(mts, period=12, robust=True).fit()\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(); plt.plot(mts.index, mts.values); plt.title('Monthly CPI — Original'); plt.tight_layout(); plt.show()\n",
    "    plt.figure(); plt.plot(stl_m.trend.index, stl_m.trend.values); plt.title('Monthly CPI — Trend'); plt.tight_layout(); plt.show()\n",
    "    plt.figure(); plt.plot(stl_m.seasonal.index, stl_m.seasonal.values); plt.title('Monthly CPI — Seasonal'); plt.tight_layout(); plt.show()\n",
    "    plt.figure(); plt.plot(stl_m.resid.index, stl_m.resid.values); plt.title('Monthly CPI — Residual'); plt.tight_layout(); plt.show()\n",
    "\n",
    "    # SARIMAX with exogenous (use forward-selected if available)\n",
    "    series_m = mclean.sort_values('Date').reset_index(drop=True)\n",
    "    endog_m = series_m['CPI_Value'].astype(float)\n",
    "\n",
    "    exog_cols_m = [c for c in mselected_fwd if c in series_m.columns]\n",
    "    exog_m = series_m[exog_cols_m].astype(float) if exog_cols_m else None\n",
    "    print('Monthly exogenous features used:', exog_cols_m)\n",
    "\n",
    "    from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "    order = (1,1,1)\n",
    "    seasonal_order = (0,1,1,12)\n",
    "    mod_m = SARIMAX(endog_m, exog=exog_m, order=order, seasonal_order=seasonal_order,\n",
    "                    enforce_stationarity=False, enforce_invertibility=False)\n",
    "    res_m = mod_m.fit(disp=False)\n",
    "    print(res_m.summary())\n",
    "\n",
    "    fitted_m = res_m.fittedvalues\n",
    "\n",
    "    # 6-month forecast\n",
    "    steps = 6\n",
    "    future_exog_m = None\n",
    "    if exog_m is not None and len(exog_cols_m) > 0:\n",
    "        last_row = exog_m.iloc[-1:]\n",
    "        future_exog_m = pd.concat([last_row]*steps, ignore_index=True)\n",
    "\n",
    "    pred_m = res_m.get_forecast(steps=steps, exog=future_exog_m)\n",
    "    mean_fc_m = pred_m.predicted_mean\n",
    "    ci_m = pred_m.conf_int()\n",
    "\n",
    "    # Build forecast index\n",
    "    last_date = series_m['Date'].iloc[-1]\n",
    "    fc_index_m = pd.date_range(last_date + pd.offsets.MonthBegin(1), periods=steps, freq='MS')\n",
    "\n",
    "    plt.figure(); plt.plot(series_m['Date'], endog_m.values, label='Actual'); plt.plot(series_m['Date'], fitted_m.values, label='Fitted'); plt.title('Monthly ARIMA/SARIMAX — Actual vs Fitted'); plt.legend(); plt.tight_layout(); plt.show()\n",
    "    plt.figure(); plt.plot(series_m['Date'], endog_m.values, label='Actual'); plt.plot(fc_index_m, mean_fc_m.values, label='Forecast'); plt.fill_between(fc_index_m, ci_m.iloc[:,0].values, ci_m.iloc[:,1].values, alpha=0.3); plt.title('Monthly ARIMA/SARIMAX — 6-Month Forecast'); plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "    # ADF on monthly\n",
    "    from statsmodels.tsa.stattools import adfuller\n",
    "    print('ADF (Monthly CPI):', {'p_value': adfuller(mts.dropna())[1]})\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print('Monthly CPI file not found at ../data/canada_cpi_monthly.csv. Add a CSV with columns [Date, CPI_Value].')\n",
    "except Exception as e:\n",
    "    print('Monthly pipeline error:', e)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
